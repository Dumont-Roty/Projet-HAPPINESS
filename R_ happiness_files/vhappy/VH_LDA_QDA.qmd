---
title: "LDA / QDA Very Happiness"
format: html
embed-resources: true
---

# Packages

```{r}
#| label: importation des packages
set.seed(123)
library(tidyverse)
library(tidymodels)
library(discrim)
library(kableExtra)
library(recipes)
library(MASS) #Modélisation LDA/QDA
library(pROC)
```

```{r}
ID_v6 <- read_csv("D:/Université de Tours/Master MEcEn/S8/8-2 Classification supervisée/Projet HAPPINESS/R_ happiness_files/vhappy/vhappy.csv",
                  na = c("", "NA"))
ID_v6 <- ID_v6 %>% mutate(across(everything(), ~replace_na(.x, "NA")))
ID_v6 <- ID_v6 %>% mutate(across(where(is.character), as.factor))

ID_v6 <- na.omit(ID_v6)
```

# LDA / QDA (tidymodels)

## Modèle linéaire (LDA)

### Echantillonage

```{r}
n <- nrow(ID_v6) #taille de la data
N <- round(2/3*n) # Taille de l'échantillon d'entrainement
train <- sample(size = N, x = 1:n) # découpage de la data train
dataTrain <- ID_v6 %>% slice(train)
dataTest <- ID_v6 %>% slice(-train)
```


### Création du modèle

```{r}
lda_spec <- discrim_linear() |> 
  set_mode("classification") |> 
  set_engine("MASS")

lda_fit <- lda_spec |> 
  fit(vhappy ~ .,data = dataTrain)
```

### Obtention de la matrice de confusion sur les données test

```{r}
lda_predict <- lda_fit %>% predict(new_data = dataTest)
```

```{r}
tab <- augment(lda_fit,new_data = dataTest) |> conf_mat(truth=vhappy,estimat=.pred_class)


tab[[1]]%>%
 matrix(nrow=nrow(.))%>%
 t()%>%
 addmargins()%>%
 as_tibble()%>%
 add_column(Réalité=c("N vhappy","vhappy","Total"),.before=1)%>%rename("N vhappy"=V1,"vhappy"=V2,Total=Sum)%>%
 kable()%>%
 add_header_above(c("","Prédiction"=2,""))%>%
 column_spec(c(4),bold=T,background="#F4F6F6",width="2cm") %>%
 column_spec(1,bold=T)%>%
 row_spec(c(3),bold=T,background="#F4F6F6") %>%
 row_spec(c(0),bold=T)%>%
 kable_styling(position="center",
 full_width=FALSE,
 bootstrap_options = "bordered",
 latex_options = "hold_position")
```

## Modèle quadratique (QDA)

### Création du modèle

```{r}
qda_spec <- discrim_quad() |> 
  set_mode("classification") |> 
  set_engine("MASS")

qda_fit <- qda_spec |> 
  fit(vhappy ~ ., data = dataTrain)
```

### Obtention matrice de confusion sur les données test

```{r}
qda_predict <- qda_fit |> predict(new_data = dataTest)
```

```{r}
tab <- augment(qda_fit,new_data = dataTest) |> conf_mat(truth=vhappy,estimat=.pred_class)

tab[[1]]%>%
 matrix(nrow=nrow(.))%>%
 t()%>%
 addmargins()%>%
 as_tibble()%>%
 add_column(Réalité=c("N vhappy","vhappy","Total"),.before=1)%>%rename("N vhappy"=V1,"vhappy"=V2,Total=Sum)%>%
 kable()%>%
 add_header_above(c("","Prédiction"=2,""))%>%
 column_spec(c(4),bold=T,background="#F4F6F6",width="2cm") %>%
 column_spec(1,bold=T)%>%
 row_spec(c(3),bold=T,background="#F4F6F6") %>%
 row_spec(c(0),bold=T)%>%
 kable_styling(position="center",
 full_width=FALSE,
 bootstrap_options = "bordered",
 latex_options = "hold_position")
```

On voit que dans les prédiction du modèle quadratique: - la modalité "Very Happy" est prédite 126 fois mais fait 77 erreurs. - la modalité "Pretty happy" est prédite 5408 fois dont `r 1720+652` erreurs. - la modalité "Not to happy" est prédite 41 fois mais fait 33 erreurs

Il y a au total 3093 bonne prédiction et 2482 erreurs de prédiction.

On a, grâce au modèle de l'analyse quadratique discriminante, un taux de bonne prédiction de `r round(3093/5575*100,2)`%

### Matrice des confusions en proportion

```{r}
#| label: matrice des confusions (proportion)
pourcent <- function(x) { 100 * x }


# Transformation et mise en forme du tableau
tab[[1]] %>%
  proportions(margin = 2) %>%
  pourcent() %>% 
  matrix(nrow = nrow(.)) %>%
  t() %>%
  addmargins(margin = 2) %>%
  as_tibble() %>%
  add_column(Réalité = c("Very Happy", "Not very Happy"), .before = 1) %>%
  rename("Very Happy" = V1,"Not very Happy" = V2, "Total" = Sum) %>%
  kable(digits = 1) %>%  # Arrondi à 1 décimale
  add_header_above(c("", "Prédiction" = 2, "")) %>%
  column_spec(4, bold = TRUE, background = "#F4F6F6", width = "2cm") %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  kable_styling(
    position = "center",
    full_width = FALSE,
    bootstrap_options = "bordered",
    latex_options = "hold_position"
  )
```

```{r}
#| label: probabilité

round(predict(qda_fit, new_data = dataTest, type = "prob"),3)
```

### Abaissement du seuil

```{r}
#| label: seuil
class20 <- ifelse(qda_predict$.pred_class>0.2, "yes", "no")  |>  as.factor()
```

```{r}
#| label: matrice des confusions 2

tab20 <- table(Réalité = dataTest$vhappy, Prédiction = class20)  |>  addmargins()

tab20 <- tab20  |>  matrix(nrow=nrow(tab20))  |> 
  as_tibble()  |> 
  add_column(Réalité=c("Very Happy", "Not very Happy", "Total"),.before=1)  |> 
  rename("Very Happy"=V1,  "Not very Happy"=V2, "Total"=V3)

tab20  |>  kable()  |>  
  add_header_above(c(" ","Prédiction" = 2," "))  |> 
  column_spec(c(4), bold = T, background ="#F4F6F6" ,width="2cm")  |> 
  column_spec(1,bold=T)  |> 
  row_spec(c(3), bold = T, background ="#F4F6F6" )  |> 
  row_spec(c(0), bold = T)  |> 
  kable_styling(position="center",full_width = FALSE,
                bootstrap_options = "bordered",
                latex_options = "hold_position")

```

# Etude des erreurs en fonction du seuil
```{r}
#| label: test-1

# Création du vecteur seuil
Seuil <- seq(0, 1, by = 0.01) # On fait varier le seuil de 0 à 0.5 

# Initialisation des vecteurs d'erreurs
ErrorI <- numeric(length(Seuil))  # Erreur de première espèce 
ErrorII <- numeric(length(Seuil)) # Erreur de seconde espèce
Error <- numeric(length(Seuil)) # Erreur globale

# Variables de réalité
Realite <- dataTest$vhappy
V <- sum(Realite == "yes")
NV <- sum(Realite == "no")

# Boucle sur les seuils
for (i in seq_along(Seuil)) {
  c <- Seuil[i]

  # Classification en fonction du seuil
  classc <- ifelse(lda.predict$posterior[, 2] > c, "yes",
                   ifelse(lda.predict$posterior[, 3] > c, "no"))
  
  # Calcul des erreurs
  Error[i] <- sum(classc != Realite) / length(Realite)  # Erreur globale
  
  ErrorI[i] <- sum((classc == "yes") & (Realite == "no")) / V # Fausse alarme
  ErrorII[i] <- sum((classc == "no") & (Realite == "yes")) / NV # Mauvaise classification
}
# Commentaire : À seuil 0, on classe tout en "very happy", puis peu à peu on classe davantage dans "pretty happy" et "not too happy".

plot(Seuil, Error, type = "l", ylim = c(0,5))
lines(Seuil, ErrorI, type = "l", lty = "dotted", col = "purple")
lines(Seuil, ErrorII, type = "l", lty = "dashed", col = "blue")
```

```{r}
#| label: test-2

# création vecteur seuil
# pour faire évoluer le seuil 
Seuil <- seq(0, 0.5, by = 0.01) # on fait varier le seuil de 0 à 0.5 

ErrorI <- NULL # erreur première espèce 
ErrorII <- NULL # erreur seconde espèce
Error <- NULL # erreur globale
i <- 1
Realite <- dataTest
N <- sum(Realite == "no")
P <- sum(Realite == "yes")

for(c in Seuil){
  classc <- ifelse(lda_predict$posterior[,2]>c, "yes", "no")
  Error[i] <- sum(classc != Realite)/1000
  ErrorI[i] <- sum((classc == "yes") & (Realite == "no"))/N # ceux qui sont classé Yes alors que en réalité sont No
  ErrorII[i] <- sum((classc == "no") & (Realite == "yes"))/P # ceux qui sont classé No alors que en réalité sont Yes
  i <- i+1
}

# à 0 comme seuil on classe tous dans Yes
# puis peu à peu on en classe davantage dans No

plot(Seuil, Error, type = "l", ylim = c(0,1))
lines(Seuil, ErrorI, type = "l", lty = "dotted", col = "orange")
lines(Seuil, ErrorII, type = "l", lty = "dashed", col = "blue")
```


# Courbe ROC avec Tidymodels


```{r}
tabroc <- roc(dataTest$vhappy, lda.predict$posterior[,1])
# compare la réalité avec les résultats des proba a posteriori
ggroc(tabroc)
auc(tabroc)
```


