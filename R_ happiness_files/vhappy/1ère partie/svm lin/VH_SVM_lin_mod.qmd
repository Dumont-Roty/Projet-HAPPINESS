---
title: "LDA / QDA Very Happiness"
format: html
---

# Packages

```{r}
#| label: importation des packages
set.seed(1)
library(wooldridge)
library(tidyverse)
library(tidymodels)
library(discrim)
library(kableExtra)
library(recipes)
library(MASS) #Modélisation LDA/QDA
library(pROC)
library(kknn)
library(doParallel)
library(future)
```
# Importation des données

```{r}
data <- read_csv("D:/Université de Tours/Master MEcEn/S8/8-2 Classification supervisée/Projet HAPPINESS/R_ happiness_files/vhappy/vhappy.csv",
                  na = c("", "NA"))
data <- data %>% mutate(across(everything(), ~replace_na(.x, "NA")))
data <- data %>% mutate(across(where(is.character), as.factor))
data <- data %>% mutate(across(where(is.logical), as.factor))
```
# % de la data
```{r}
n <- nrow(data) #taille de la data
N <- round(1/2*n) # Taille de l'échantillon d'entrainement
train <- sample(1:n, size = N) # découpage de la data train
data2 <- data %>% slice(train)
```


# Echantillonage 

```{r}
set.seed(1)
data_split <- initial_split(data2, prop = 0.75, strata = vhappy) # classique 3 quart / 1 quart
train_data <- training(data_split)
test_data <- testing(data_split)
```

## Construction des différents modèles

### recette à appliquer 

```{r}
# dat_rec <- train_data |> recipe(vhappy~educ+kids+tvhours) #TROP LOOOOOOOOOOOONG

dat_rec <- train_data  %>% recipe(vhappy~.) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  #step_dummy(all_nominal_predictors()) %>% 
  step_other(all_nominal_predictors(), threshold = 0.05) %>% 
  step_zv(all_predictors()) %>% 
  step_corr(all_numeric_predictors(), threshold = 0.9)
```

```{r}
#| label: Définition du modèle SVM linéaire 

svm_linear_mod <- svm_linear() |> 
  set_mode("classification") |> 
  set_engine("kernlab")
```

```{r}
svm_linear_wf <- workflow() |> 
  add_model(svm_linear_mod |> set_args(cost = tune())) |> 
  add_recipe(dat_rec)
```

### Echantillonage pour l'optimisation des paramètres

Pour l'optimisation des hyper paramètres --> ADOCK
```{r}
dat_folds <- vfold_cv(train_data, v = 5, strata = vhappy)
```


Grille pour l’optimisation du paramètre svm linéaire.

```{r}
# nombre de coeurs 
n_core <- parallel::detectCores(logical = TRUE)
#
plan(multisession, workers = parallel::detectCores() - 1)
# on laisse un coeur pour le reste
# réalisation des commandes nécéssitant la parallélisation

svm_lin_grid <- grid_regular(cost(), levels = 5)
tune_res_svm_lin <- tune_grid(svm_linear_wf,
                              resamples = dat_folds,
                              grid = svm_lin_grid,
                              metrics = metric_set(roc_auc))

plan(sequential)
```

```{r}
autoplot(tune_res_svm_lin)
```

On selectionne la meilleur valeur de margin :

```{r}
svm_lin_final_wf <- svm_linear_wf |> finalize_workflow((tune_res_svm_lin |> select_best(metric = "roc_auc")))
```


Les paramètres sont optimisés on peut maintenant faire travailler les modèles sur les données d'apprentissage et comparer les qualités des modèles sur les données test.

```{r}
collect <- function(x){
  last_fit(x,split = data_split) |> # "je veux travailler sur tel truc en sachant le partage de donnée"
    collect_predictions()
}
```

```{r}
svm_lin_result <- svm_lin_final_wf |> collect()
```

On va construitre un tableau qui continent les résultats pour chaque individus de la base de donnée testing, en fonctioon de la méthode utilisé
Pour chasue individu : - résultat, -méthode utilisé


Comparons les modèles :

```{r}
svm_lin_result |> roc_curve(vhappy, .pred_no) |> autoplot()
roc(test_data$vhappy, svm_lin_result$.pred_no) %>% auc()
```
Si proche de la bissectrice, le hasard est aussi bon que le modèle.

```{r}
save(svm_linear_mod,svm_linear_wf,dat_folds,svm_lin_grid,tune_res_svm_lin,svm_lin_final_wf,svm_lin_result, file = "model_svm_lin.RData")
```

