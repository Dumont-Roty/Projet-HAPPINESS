---
title: "LDA / QDA Very Happiness"
format: html
---

# Packages

```{r}
#| label: importation des packages
set.seed(123)
library(tidyverse)
library(tidymodels)
library(discrim)
library(kableExtra)
library(recipes)
library(MASS) #Modélisation LDA/QDA
library(pROC)
library(kknn)
library(doParallel)
library(FactoMineR)
library(future)
```

# Importation des données

```{r}
data <- read_csv("D:/Université de Tours/Master MEcEn/S8/8-2 Classification supervisée/Projet HAPPINESS/R_ happiness_files/vhappy/vhappy.csv",
                  na = c("", "NA"))
data <- data %>% mutate(across(everything(), ~replace_na(.x, "NA")))
data <- data %>% mutate(across(where(is.character), as.factor))
data <- data %>% mutate(across(where(is.logical), as.factor))
```
```{r}
ID_MCA <- data[, sapply(data, is.factor)]

res.mca <- MCA(ID_MCA, graph = FALSE)  # Stocker les résultats sans affichage direct
plot(res.mca, choix = "ind")  # Graphique des individus
plot(res.mca, choix = "var")  # Graphique des variables
```


# Echantillonage 
```{r}
set.seed(1)

data_split <- data |> initial_split(prop = 3/4)
test_data <- data_split |> testing()
train_data <- data_split |> training()
```


## Construction des différents modèles

### recette à appliquer 

```{r}
# dat_rec <- train_data |> recipe(vhappy~educ+kids+tvhours) #TROP LOOOOOOOOOOOONG

dat_rec <- train_data  %>% recipe(vhappy~.) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  #step_dummy(all_nominal_predictors()) %>% 
  step_other(all_nominal_predictors(), threshold = 0.05) %>% 
  step_zv(all_predictors()) %>% 
  step_corr(all_numeric_predictors(), threshold = 0.9)
```
### Définition des modèles :

```{r}
#| label: Définition des 5 modèles 

knn_mod <- nearest_neighbor() |> 
  set_mode("classification") |> 
  set_engine("kknn")
```

```{r}
knn_wf <- workflow() |> 
  add_model(knn_mod |> set_args(neighbors = tune())) |> 
  add_recipe(dat_rec)
```

### Echantillonage pour l'optimisation des paramètres

Pour l'optimisation des hyper paramètres --> ADOCK
```{r}
dat_folds <- vfold_cv(train_data, v = 5, strata = vhappy) # 5 couches qui respectent tjrs le nombre gens très heureux
```

### Grille pour tester les hyper paramètres

```{r}
# nombre de coeurs 
n_core <- parallel::detectCores(logical = TRUE)
#
plan(multisession, workers = parallel::detectCores() - 1)
# on laisse un coeur pour le reste
# réalisation des commandes nécéssitant la parallélisation

knn_grid <- grid_regular(neighbors(range = c(1,15)), levels = 10)
tune_res_knn <- tune_grid(knn_wf,
                          resamples = dat_folds,
                          grid = knn_grid)

autoplot(tune_res_knn) # necessite le package kknn

plan(sequential)
```

Si on choisit la metrique (air sous la courbe ROC), on peut se poser la question suivante :
Quelle est la meilleur valeur de K pour l'air sous la courbe ROC ?

Le sur apprentissage est l'inverse de k pour les plus proche voisins 

On selectionne le meileur modèle :

```{r}
knn_best <- tune_res_knn |> select_best(metric = "roc_auc")
```

On peut finaliser le modèle knn :

```{r}
knn_final_wf <- knn_wf |> finalize_workflow(knn_best)
```


```{r}
collect <- function(x){
  last_fit(x,split = data_split) |> # "je veux travailler sur tel truc en sachant le partage de donnée"
    collect_predictions()
}
```

```{r}
knn_result <- knn_final_wf |> collect()
```

On va construitre un tableau qui continent les résultats pour chaque individus de la base de donnée testing, en fonctioon de la méthode utilisé
Pour chasue individu : - résultat, -méthode utilisé


Comparons les modèles :

```{r}
knn_result |> roc_curve(vhappy, .pred_no) |> autoplot()
roc(test_data$vhappy, knn_result$.pred_no) %>% auc()
```
Si proche de la bissectrice, le hasard est aussi bon que le modèle.


```{r}
save(knn_mod,knn_wf,dat_folds,knn_grid,tune_res_knn,knn_best,knn_final_wf,collect,knn_result, file = "model_KNN.RData")
```